
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>LogisticRegression &mdash; pyVision 0.0.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="pyVision 0.0.1 documentation" href="../index.html" />
    <link rel="up" title="Module code" href="index.html" />
  
   
       <script type="text/javascript" src="../_static/sidebar.js"></script>
   
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/_modules/LogisticRegression.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
    var bodywrapper = $('.bodywrapper');
    var sidebarbutton = $('#sidebarbutton');
    sidebarbutton.css({'height': '900px'});
  </script>

  </head>
  <body>


<div class="header-wrapper">
    <div class="header"><div class="navbar">
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="https://github.com/pi19404/OpenVision">Source</a></li>            
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/pi19404/OpenVision">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="../py-modindex.html"
        >Modules
        <br/>
        <span class="smallrellink">
        Python Module In...
        </span>
            <span class="hiddenrellink">
            Python Module Index
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="index.html">
        Up
        <br/>
        <span class="smallrellink">
        Module code
        </span>
            <span class="hiddenrellink">
            Module code
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version">This documentation is for pyVision <strong>version 0.0.1</strong> &mdash; </p>
    <p class="citing">If you use the software, please consider citing pyVision</a>.</p>
    
    </div>
</div>



      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <h1>Source code for LogisticRegression</h1><div class="highlight"><pre>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Logistic Regression</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c"># Author: pi19404 &lt;pi19404@gmail.com&gt;</span>
<span class="c">#         </span>
<span class="c">#       </span>
<span class="c">#        </span>
<span class="c">#         </span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="kn">as</span> <span class="nn">met</span>
<span class="kn">import</span> <span class="nn">LoadDataSets</span>
<span class="c"># Minimization routines</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="kn">import</span> <span class="nn">pyvision_common</span> <span class="kn">as</span> <span class="nn">pyvision</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">izip</span> 
<span class="kn">import</span> <span class="nn">Optimizer</span>
    

<span class="s">&quot; The class encaspulates the Logistic Regression Classification Algorithms &quot;</span>
<div class="viewcode-block" id="LogisticRegression"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression">[docs]</a><span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
       
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">Regularization</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">eta</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; initialize the parametes of the model &quot;&quot;&quot;</span> 
        <span class="k">if</span><span class="p">(</span><span class="n">n_in</span><span class="o">!=</span><span class="mi">0</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="o">=</span><span class="n">n_out</span><span class="p">;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">=</span><span class="n">n_in</span><span class="p">;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_parameters</span><span class="p">(</span><span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">);</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">=</span><span class="p">[];</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">=</span><span class="p">[];</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">=</span><span class="p">[];</span>
            
        <span class="k">if</span><span class="p">(</span><span class="n">labels</span><span class="o">==</span><span class="bp">None</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">=</span><span class="nb">xrange</span><span class="p">(</span><span class="n">n_out</span><span class="p">);</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">Regularization</span><span class="o">=</span><span class="n">Regularization</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">;</span>
    
      
    <span class="sd">&quot;&quot;&quot;function to initialize the parameters of the model &quot;&quot;&quot;</span>      
<div class="viewcode-block" id="LogisticRegression.initialize_parameters"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.initialize_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_in</span><span class="p">,</span><span class="n">n_out</span><span class="p">):</span>
        <span class="k">print</span> <span class="s">&quot;initializing the parameters of logistic regression&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span><span class="o">=</span><span class="n">n_out</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">=</span><span class="n">n_in</span><span class="p">;</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_out</span><span class="p">,</span><span class="n">n_in</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">);</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_out</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">);</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_out</span><span class="p">,</span><span class="n">n_in</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">);</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">flatten</span><span class="p">();</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nparams</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        
        <span class="c">#print np.shape(self.W),np.shape(self.b)</span>
       
       </div>
    <span class="sd">&quot;&quot;&quot; function predicts the probability of input vector x&quot;&quot;&quot;</span>
    <span class="sd">&quot;&quot;&quot; the output y is MX1 vector (M is no of classse) &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.predict"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>  
        <span class="n">y</span><span class="o">=</span><span class="n">pyvision</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,</span><span class="n">x</span><span class="p">);</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">=</span><span class="n">y</span><span class="p">;</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">;</span>
</div>
    <span class="sd">&quot;&quot;&quot; function used for label assigment and output probability for predicted index &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.lable"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.lable">[docs]</a>    <span class="k">def</span> <span class="nf">lable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">y</span><span class="p">];</span>
</div>
<div class="viewcode-block" id="LogisticRegression.probability"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.probability">[docs]</a>    <span class="k">def</span> <span class="nf">probability</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="n">y</span><span class="p">];</span>
        
        </div>
    <span class="sd">&quot;&quot;&quot; function classifies the input vector x into one of output lables &quot;&quot;&quot;</span>
    <span class="sd">&quot;&quot;&quot; input is NXD vector then output is NX1 vector &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.classify"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.classify">[docs]</a>    <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">result</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
        <span class="n">indices</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">);</span>
        <span class="c">#converting indices to lables</span>
        <span class="n">lablels</span><span class="o">=</span><span class="nb">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lable</span><span class="p">,</span> <span class="n">indices</span><span class="p">);</span>
        <span class="k">return</span> <span class="n">lablels</span><span class="p">;</span>     
        </div>
<div class="viewcode-block" id="LogisticRegression.vector_mul"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.vector_mul">[docs]</a>    <span class="k">def</span> <span class="nf">vector_mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">;</span>
        </div>
    <span class="sd">&quot;&quot;&quot; function computes the negative log likelyhood over input dataset </span>
<span class="sd">         params is optional argument to pass parameter to classifier </span>
<span class="sd">        ,useful in cases of iterative optimization routines for function evaluations like scipy.optimization package &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.negative_log_likelihood"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.negative_log_likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">negative_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c"># args contains the training data</span>
        <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">;</span>
                 
        <span class="bp">self</span><span class="o">.</span><span class="n">update_params</span><span class="p">(</span><span class="n">params</span><span class="p">);</span>
        <span class="n">sigmoid_activation</span> <span class="o">=</span> <span class="n">pyvision</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,</span><span class="n">x</span><span class="p">);</span>
        <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">sigmoid_activation</span><span class="p">)[</span><span class="mi">0</span><span class="p">]),</span><span class="n">y</span><span class="p">];</span>
        <span class="n">p</span><span class="o">=</span><span class="n">sigmoid_activation</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">l</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">));</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Regularization</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
            <span class="n">l</span><span class="o">=</span><span class="n">l</span><span class="o">+</span><span class="mf">0.5</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">**</span><span class="mi">2</span><span class="p">);</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Regularization</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">l</span><span class="o">=</span><span class="n">l</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">));</span>
        
        
        <span class="k">return</span> <span class="n">l</span><span class="p">;</span>
<span class="c">##        self.validate(self.x,self.y)     </span></div>
    <span class="sd">&quot;&quot;&quot; function to set the training data for current computation loop&quot;&quot;&quot;</span>
    <span class="sd">&quot;&quot;&quot; useful in running algorithms for batch processing &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.set_training_data"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.set_training_data">[docs]</a>    <span class="k">def</span> <span class="nf">set_training_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">;</span>
</div>
    <span class="sd">&quot;&quot;&quot; function to compute the gradient of parameters for a single data sample &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.compute_gradients"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.compute_gradients">[docs]</a>    <span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">out</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">out</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)));</span>                
        <span class="n">out</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">=</span><span class="n">out</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>   
        <span class="n">W</span><span class="o">=</span><span class="n">out</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Regularization</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
           <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Regularization</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">W</span><span class="p">);</span>
           <span class="c">#print np.shape(r),np.shape(W)</span>
           <span class="c">#dd</span>
        <span class="n">res</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">out</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
        
</div>
    <span class="sd">&quot;&quot;&quot; function to compute the gradient of loss function over all input samples</span>
<span class="sd">        params is optional input parameter passed to the classifier,which is useful in cases </span>
<span class="sd">        of iterative optimization routines,added for compatiblity with scipi.optimization package &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.gradients"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.gradients">[docs]</a>    <span class="k">def</span> <span class="nf">gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c"># args contains the training data</span>
        <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_params</span><span class="p">(</span><span class="n">params</span><span class="p">);</span>
        <span class="n">sigmoid_activation</span> <span class="o">=</span> <span class="n">pyvision</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,</span><span class="n">x</span><span class="p">);</span>        
        <span class="n">e</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span><span class="n">b</span> <span class="ow">in</span> <span class="n">izip</span><span class="p">(</span><span class="n">sigmoid_activation</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">)]</span>                         
        <span class="n">mean1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">e</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">);</span>        
        <span class="n">mean1</span><span class="o">=</span><span class="n">mean1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">();</span>
        <span class="k">return</span> <span class="n">mean1</span><span class="p">;</span>
</div>
    <span class="sd">&quot;&quot;&quot; function to retrieve the params &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.get_params"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.get_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">;</span>

</div>
    <span class="sd">&quot;&quot;&quot; function to set the params &quot;&quot;&quot;</span>        
<div class="viewcode-block" id="LogisticRegression.set_params"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.set_params">[docs]</a>    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">;</span>
        
    
</div>
    <span class="sd">&quot;&quot;&quot; function to update the weights given parameter array &quot;&quot;&quot;</span>        
<div class="viewcode-block" id="LogisticRegression.update_params"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.update_params">[docs]</a>    <span class="k">def</span> <span class="nf">update_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">params</span><span class="o">==</span><span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">;</span>
        <span class="n">nparam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        <span class="n">param1</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">nparam</span><span class="p">);</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">=</span><span class="n">param1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">nparam</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">=</span><span class="n">param1</span><span class="p">[:,</span><span class="n">nparam</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        
        </div>
    <span class="sd">&quot;&quot;&quot; function to update the parameter array given weights &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.update_params_grads"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.update_params_grads">[docs]</a>    <span class="k">def</span> <span class="nf">update_params_grads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
        <span class="n">nparam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        <span class="n">param1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">nparam</span><span class="p">);</span>
        <span class="n">param1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">nparam</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="n">W</span><span class="p">;</span>
        <span class="n">param1</span><span class="p">[:,</span><span class="n">nparam</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="n">b</span><span class="p">;</span>
        <span class="k">return</span> <span class="n">param1</span><span class="o">.</span><span class="n">flatten</span><span class="p">();</span>
   </div>
    <span class="sd">&quot;&quot;&quot; callback function from the optimizer ,can be used to display status,update parameters&quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.callback"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.callback">[docs]</a>    <span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">num</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">flag</span><span class="p">,</span><span class="n">eta</span><span class="p">,</span><span class="n">error</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>       
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">=</span><span class="n">w</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">);</span>
        <span class="k">if</span> <span class="n">flag</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">&quot;iteration   : &quot;</span><span class="p">,</span><span class="n">num</span><span class="p">,</span><span class="s">&quot;:&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">w</span><span class="p">);</span>
            <span class="n">l</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">negative_log_likelihood</span><span class="p">(</span><span class="n">w</span><span class="p">);</span>
            <span class="k">print</span> <span class="s">&quot;Loss function   : &quot;</span><span class="p">,</span><span class="n">l</span><span class="p">;</span>
        </div>
    <span class="sd">&quot;&quot;&quot; the function that performs learning,computing gradients and updating parameters &quot;&quot;&quot;</span>
<div class="viewcode-block" id="LogisticRegression.learn"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.learn">[docs]</a>    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">update</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">grads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gradients</span><span class="p">();</span>
        <span class="n">params</span><span class="o">=</span><span class="p">[];</span>
        <span class="k">if</span> <span class="n">update</span><span class="o">!=</span><span class="bp">None</span><span class="p">:</span>
            <span class="n">params</span><span class="o">=</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span><span class="n">grads</span><span class="p">)</span>
        <span class="n">nparam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">+</span><span class="mi">1</span><span class="p">;</span>
        <span class="n">error</span><span class="o">=</span><span class="n">grads</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">nparam</span><span class="p">)[:,</span><span class="n">nparam</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>  
        <span class="k">return</span> <span class="p">[</span><span class="n">params</span><span class="p">,</span><span class="n">error</span><span class="p">];</span>

</div>
    <span class="sd">&quot;&quot;&quot; the function performs training for logistic regression classifier &quot;&quot;&quot;</span>        
<div class="viewcode-block" id="LogisticRegression.train"><a class="viewcode-back" href="../LogisticRegression.html#LogisticRegression.LogisticRegression.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="n">validate</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_dimensions</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>            
            <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> 
            <span class="n">n_dimensions</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">];</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_parameters</span><span class="p">(</span><span class="n">n_dimensions</span><span class="p">,</span><span class="n">n_classes</span><span class="p">);</span>
                
        <span class="n">opti</span><span class="o">=</span><span class="n">Optimizer</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="s">&quot;SGD&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2000</span><span class="p">,</span><span class="mf">0.13</span><span class="p">,</span><span class="mi">2000</span><span class="o">*</span><span class="mf">0.99</span><span class="p">);</span>    
        <span class="n">opti</span><span class="o">.</span><span class="n">set_datasets</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="n">validate</span><span class="p">);</span>
        <span class="n">opti</span><span class="o">.</span><span class="n">set_functions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">negative_log_likelihood</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">set_training_data</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">classify</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="p">,</span><span class="bp">None</span><span class="p">,</span><span class="bp">None</span><span class="p">);</span>
        <span class="n">opti</span><span class="o">.</span><span class="n">run</span><span class="p">();</span>
            
        <span class="c">#self.labels =np.unique(train[1]);</span>
        <span class="c">#sgd1=sgd.SGD(0.13,600,1000);</span>
        <span class="c">#sgd1.set_datasets(train,test,validate);</span>
        <span class="c">#sgd1.set_functions(self.classify,self.gradients,self.get_params,self.callback);</span>
        
        <span class="c">#sgd1.run();</span>
        
      </div></div>
<span class="sd">&quot;&quot;&quot; main test function &quot;&quot;&quot;</span>
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>    
     <span class="n">model_name1</span><span class="o">=</span><span class="s">&quot;/home/pi19404/Documents/mnist.pkl.gz&quot;</span>
     <span class="n">data</span><span class="o">=</span><span class="n">LoadDataSets</span><span class="o">.</span><span class="n">LoadDataSets</span><span class="p">();</span>
     <span class="c">#[train,test,validate]=data.load_pickle_data(model_name1);</span>
     <span class="p">[</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="n">validate</span><span class="p">]</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">load_sklearn_data</span><span class="p">(</span><span class="s">&quot;digits&quot;</span><span class="p">);</span>
     
     <span class="n">x</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">borrow</span><span class="o">=</span><span class="bp">True</span><span class="p">);</span>
     <span class="n">y</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>     
     <span class="n">train</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5000</span><span class="p">],</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5000</span><span class="p">]];</span>
     <span class="c">#train=[x,y];</span>

     <span class="n">x</span><span class="o">=</span><span class="n">test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">borrow</span><span class="o">=</span><span class="bp">True</span><span class="p">);</span>
     <span class="n">y</span><span class="o">=</span><span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>
     <span class="n">test</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">];</span>
     
     <span class="n">x</span><span class="o">=</span><span class="n">validate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">borrow</span><span class="o">=</span><span class="bp">True</span><span class="p">);</span>
     <span class="n">y</span><span class="o">=</span><span class="n">validate</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>
     <span class="n">validate</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">];</span>
     
     <span class="n">classifier</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">);</span>
     <span class="n">classifier</span><span class="o">.</span><span class="n">Regularization</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span>
     <span class="n">classifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="n">validate</span><span class="p">);</span>

     <span class="k">print</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>
     
     
     
     
     
    
<span class="c">#softmax(numpy.array([1,1],[2,2],[3,3]),numpy.array([1,1,1]),numnp.array([1,2]))</span>
</pre></div>

          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2014, pi19404.
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="../py-modindex.html">Previous
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>